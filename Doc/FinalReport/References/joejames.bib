@unpublished{ALGLIB,
    author = {Sergey Bochkanov},
    title = {ALGLIB},
    url = {www.alglib.net},
	annote = {ALGLIB is a cross-platform numerical analysis and data processing library. I intended to use this for data analysis.}
}

@unpublished{GNULGPL,
	author = {GNU Project - Free Software Foundation},
	citeulike-article-id = {14025402},
	citeulike-linkout-0 = {https://www.gnu.org/copyleft/lesser.html},
	keywords = {license},
	posted-at = {2016-05-01 12:08:20},
	priority = {2},
	title = {{GNU Lesser General Public License v3.0}},
	url = {https://www.gnu.org/copyleft/lesser.html}
}


@book{MultipleViewGeometry,
	annote ={A book describing how to reconstruct scenes from images using geometry and algebra, with applications to computer vision. The particular section that is relevant to the project would be Part 0, section 4.},
	abstract = {{How to reconstruct scenes from images using geometry and algebra, with applications to computer vision.}},
	author = {Hartley, Richard and Zisserman, Andrew},
	citeulike-article-id = {352536},
	citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0521540518},
	citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0521540518},
	citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0521540518},
	citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0521540518},
	citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0521540518/citeulike00-21},
	citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0521540518},
	citeulike-linkout-6 = {http://www.worldcat.org/isbn/0521540518},
	citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0521540518},
	citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0521540518\&index=books\&linkCode=qs},
	citeulike-linkout-9 = {http://www.librarything.com/isbn/0521540518},
	day = {19},
	edition = {2},
	howpublished = {Paperback},
	isbn = {9780521540513},
	keywords = {3d-vision, vision},
	month = apr,
	posted-at = {2005-10-17 04:24:55},
	priority = {2},
	publisher = {Cambridge University Press},
	title = {{Multiple View Geometry in Computer Vision}},
	url = {http://www.worldcat.org/isbn/0521540518},
	year = {2004}
}


@inproceedings{Lucas_KanadeOF,
	abstract = {{Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system.}},
	address = {San Francisco, CA, USA},
	author = {Lucas, Bruce D. and Kanade, Takeo},
	booktitle = {Proceedings of the 7th International Joint Conference on Artificial Intelligence - Volume 2},
	citeulike-article-id = {9317229},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1623280},
	keywords = {registration},
	location = {Vancouver, BC, Canada},
	pages = {674--679},
	posted-at = {2013-01-29 14:05:47},
	priority = {2},
	publisher = {Morgan Kaufmann Publishers Inc.},
	series = {IJCAI'81},
	title = {{An Iterative Image Registration Technique with an Application to Stereo Vision}},
	url = {http://portal.acm.org/citation.cfm?id=1623280},
	year = {1981},
	annote = {The Lucas-Kanade optical flow algorithm that can deal with rotation, scaling and shearing.}
}


@unpublished{StereoDepth,
	author = {Nair, Dinesh},
	citeulike-article-id = {14024288},
	citeulike-linkout-0 = {http://www.techbriefs.com/component/content/article/ntb/features/feature-articles/14925},
	day = {01},
	keywords = {vison},
	month = oct,
	note = {Last accessed 29/04/2016},
	posted-at = {2016-04-29 17:39:21},
	priority = {2},
	title = {{A Guide to Stereovision and 3D Imaging - Nasa Tech Briefs :: NASA Tech Briefs}},
	url = {http://www.techbriefs.com/component/content/article/ntb/features/feature-articles/14925},
	year = {2012},
	annote = {A guide on stereoscopic cameras and 3D vision.}
}

@techreport{Nstandard,
	abstract = {{This amendment defines modifications to both the IEEE 802.11 physical layer (PHY) and the IEEE 802.11 medium access control (MAC) sublayer so that modes of operation can be enabled that are capable of much higher throughputs, with a maximum throughput of at least 100 Mb/s, as measured at the MAC data service access point (SAP).}},
	citeulike-article-id = {9626335},
	citeulike-linkout-0 = {http://dx.doi.org/10.1109/ieeestd.2009.5307322},
	citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5307322},
	doi = {10.1109/ieeestd.2009.5307322},
	isbn = {978-0-7381-6047-4},
	keywords = {802standard, mmp},
	month = oct,
	pages = {1--565},
	posted-at = {2016-04-25 17:56:49},
	priority = {2},
	publisher = {IEEE},
	title = {{IEEE Standard for Information technology-- Local and metropolitan area networks-- Specific requirements-- Part 11: Wireless LAN Medium Access Control (MAC)and Physical Layer (PHY) Specifications Amendment 5: Enhancements for Higher Throughput}},
	url = {http://dx.doi.org/10.1109/ieeestd.2009.5307322},
	year = {2009},
	annote = {The IEEE standard for Wi-Fi 802.11.}
}

@incollection{fuzzyRANSAC,
    annote= {This is a method of performing RANSAC using fuzzy logic to calculate a homography matrix.},
    author = {Lee, Joongjae and Kim, Gyeyoung},
    booktitle = {Computational Science and Its Applications â€“ ICCSA 2007},
    citeulike-article-id = {14011855},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-74472-6\_81},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-540-74472-6\_81},
    doi = {10.1007/978-3-540-74472-6\_81},
    editor = {Gervasi, Osvaldo and Gavrilova, MarinaL},
    keywords = {development, mmp, ransac},
    pages = {992--1002},
    posted-at = {2016-04-14 11:16:28},
    priority = {3},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Robust Estimation of Camera Homography Using Fuzzy RANSAC}},
    url = {http://dx.doi.org/10.1007/978-3-540-74472-6\_81},
    volume = {4705},
    year = {2007}
}

@inproceedings{DenseInterest,
    annote = {This paper goes through methods of calculating dense interest points, using regular grid sampling techniques.},
    author = {Tuytelaars, Tinne},
    booktitle = {Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
    citeulike-article-id = {13971358},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/cvpr.2010.5539911},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5539911},
    doi = {10.1109/cvpr.2010.5539911},
    institution = {ESAT-PSI, K.U. Leuven, Leuven, Germany},
    isbn = {978-1-4244-6984-0},
    issn = {1063-6919},
    keywords = {features, mmp, vision},
    month = jun,
    pages = {2281--2288},
    posted-at = {2016-03-07 12:06:41},
    priority = {2},
    publisher = {IEEE},
    title = {{Dense interest points}},
    url = {http://dx.doi.org/10.1109/cvpr.2010.5539911},
    year = {2010}
}

@inproceedings{PhoneObstacleAvoidance,
    author = {Tapu, Ruxandra and Mocanu, Bogdan and Bursuc, Andrei and Zaharia, T.},
    booktitle = {Computer Vision Workshops (ICCVW), 2013 IEEE International Conference on},
    citeulike-article-id = {13969033},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/iccvw.2013.65},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6755931},
    doi = {10.1109/iccvw.2013.65},
    institution = {ARTEMIS Dept., IT/Telecom SudParis, Evry, France},
    keywords = {mmp, optical-flow, vision},
    month = dec,
    annote = {An algorithm essentially performing what I want, applied to a mobile phone in motion.},
    pages = {444--451},
    posted-at = {2016-03-06 14:44:42},
    priority = {2},
    publisher = {IEEE},
    title = {{A Smartphone-Based Obstacle Detection and Classification System for Assisting Visually Impaired People}},
    url = {http://dx.doi.org/10.1109/iccvw.2013.65},
    year = {2013}
}

@inproceedings{3DMapOpFlowMono,
    annote = {A method of 3D reconstruction using a single camera.},
    author = {Diskin, Yakov and Asari, Vijayan K.},
    booktitle = {Applied Imagery Pattern Recognition Workshop (AIPR): Sensing for Control and Augmentation, 2013 IEEE},
    citeulike-article-id = {13948197},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/aipr.2013.6749315},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6749315},
    doi = {10.1109/aipr.2013.6749315},
    institution = {Center of Excellence for Comput. Vision \& Wide Area Surveillance Res., Univ. of Dayton, Dayton, OH, USA},
    keywords = {mmp, vision},
    month = oct,
    pages = {1--6},
    posted-at = {2016-03-02 00:40:24},
    priority = {2},
    publisher = {IEEE},
    title = {{Dense 3D point-cloud model using optical flow for a monocular reconstruction system}},
    url = {http://dx.doi.org/10.1109/aipr.2013.6749315},
    year = {2013}
}

@article{CVDrone,
    author = {Puku0x},
    citeulike-article-id = {13948040},
    howpublished = {https://github.com/puku0x/cvdrone},
    keywords = {api, development, drone, mmp, vision},
    annote = {A middleware for the AR Drone 2.0 that combines openCV and drone control.},
    posted-at = {2016-03-01 22:04:11},
    priority = {0},
    title = {{CV Drone (= OpenCV + AR.Drone)}}
}

@article{ROSDrone,
    author = {Hamer, Mike and Engel, Jakob and Parekh, Sameer},
    citeulike-article-id = {13948038},
    citeulike-linkout-0 = {http://wiki.ros.org/ardrone\_autonomy},
    howpublished = {https://github.com/AutonomyLab/ardrone\_autonomy},
    keywords = {api, drone, mmp},
    annote = {A potential method to control the drone.},
    posted-at = {2016-03-01 21:58:24},
    priority = {0},
    title = {{ardrone\_autonomy - ROS driver for Parrot AR-Drone 1.0 and 2.0 quadrocopters}},
    url = {http://wiki.ros.org/ardrone\_autonomy}
}

@article{nodecop,
    author = {Geisend\"{o}rfer, Felix and Mehner, Robin and Ball, Thorsten and Kosch\"{u}tzki, Tim and Nesbitt, Andrew and Besser, Matti and Buca, Katharina},
    citeulike-article-id = {13948026},
    citeulike-linkout-0 = {http://www.nodecopter.com/},
    howpublished = {https://github.com/felixge/node-ar-drone},
    keywords = {api, drone, mmp},
    annote = {Method of accessing and controlling the AR Drone 2.0 through javascript},
    posted-at = {2016-03-01 21:42:59},
    priority = {0},
    title = {{The NodeCopter - Programming flying robots with node.js}},
    url = {http://www.nodecopter.com/}
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {13947989},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import, *file-import-16-03-01},
    posted-at = {2016-03-01 20:39:26},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000},
    annote = {An open source computer vision library, providing access to vision algorithms, data types and GUI elements that are necessary for computer vision.}
}

@unpublished{citeulike:13944234,
    author = {Puku0x},
    citeulike-article-id = {13944234},
    citeulike-linkout-0 = {https://github.com/puku0x/cvdrone},
    keywords = {development, drone, vision},
    annote = {The CVDrone github repository. A piece of software for beginners that allows for easy control of the AR.Drone and OpenCV.},
    posted-at = {2016-02-29 11:47:33},
    priority = {2},
    title = {{CVDrone: OpenCV + AR Drone}},
    url = {https://github.com/puku0x/cvdrone}
}

@article{opticalFlowBirds,
    abstract = {{Although considerable effort has been devoted to investigating how birds migrate over large distances, surprisingly little is known about how they tackle so successfully the moment-to-moment challenges of rapid flight through cluttered environments [1]. It has been suggested that birds detect and avoid obstacles [2] and control landing maneuvers [35] by using cues derived from the image motion that is generated in the eyes during flight. Here we investigate the ability of budgerigars to fly through narrow passages in a collision-free manner, by filming their trajectories during flight in a corridor where the walls are decorated with various visual patterns. The results demonstrate, unequivocally and for the first time, that birds negotiate narrow gaps safely by balancing the speeds of image motion that are experienced by the two eyes and that the speed of flight is regulated by monitoring the speed of image motion that is experienced by the two eyes. These findings have close parallels with those previously reported for flying insects [613], suggesting that some principles of visual guidance may be shared by all diurnal, flying animals. Âº Birds regulate flight speed by monitoring induced image motion (optic flow) Âº Birds negotiate narrow passages safely by balancing lateral optic flow signals}},
    author = {Bhagavatula, Partha S. and Claudianos, Charles and Ibbotson, Michael R. and Srinivasan, Mandyam V.},
    citeulike-article-id = {9976388},
    citeulike-linkout-0 = {http://www.cell.com/current-biology/abstract/S0960-9822(11)01010-4},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.cub.2011.09.009},
    day = {8},
    doi = {10.1016/j.cub.2011.09.009},
    issn = {09609822},
    journal = {Current Biology},
    keywords = {mmp, vision},
    month = nov,
    number = {21},
    pages = {1794--1799},
    posted-at = {2016-02-27 13:15:00},
    priority = {2},
    publisher = {Cell Press},
    title = {{Optic Flow Cues Guide Flight in Birds}},
    url = {http://dx.doi.org/10.1016/j.cub.2011.09.009},
    volume = {21},
    year = {2011},
    annote={A paper showing how birds regulate their flight and avoid collisions in corridors using optical flow.}
}

@article{citeulike:9515178,
    abstract = {{Flying insects display remarkable agility, despite their diminutive eyes and brains. This review describes our growing understanding of how these creatures use visual information to stabilize flight, avoid collisions with objects, regulate flight speed, detect and intercept other flying insects such as mates or prey, navigate to a distant food source, and orchestrate flawless landings. It also outlines the ways in which these insights are now being used to develop novel, biologically inspired strategies for the guidance of autonomous, airborne vehicles. \^{a}Â–Âº Flying insects rely heavily on cues derived from image motion. \^{a}Â–Âº These cues are used to stabilise flight, avoid collisions, and guide landings. \^{a}Â–Âº Vision is also crucial in long-range navigation. \^{a}Â–Âº These biological insights are spawning novel aircraft guidance systems.}},
    author = {Srinivasan, Mandyam V.},
    citeulike-article-id = {9515178},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.conb.2011.05.020},
    comment = {This article explains the usefulness of particular vision techniques and how they're used in nature.},
    doi = {10.1016/j.conb.2011.05.020},
    issn = {09594388},
    journal = {Current Opinion in Neurobiology},
    keywords = {mmp, vision},
    month = aug,
    number = {4},
    pages = {535--543},
    posted-at = {2016-02-27 13:08:45},
    priority = {2},
    title = {{Visual control of navigation in insects and its relevance for robotics}},
    url = {http://dx.doi.org/10.1016/j.conb.2011.05.020},
    volume = {21},
    year = {2011},
    annote = {A paper describing the current knowledge on how insects use optical flow for flight.}
}

@unpublished{PersonalScrum,
    author = {Pruitt, John},
    citeulike-article-id = {13940453},
    citeulike-linkout-0 = {http://blog.jgpruitt.com/tag/personal-scrum/},
    howpublished = {http://blog.jgpruitt.com/tag/personal-scrum/},
    keywords = {methodology, mmp, process},
    annote = {A blog of a grduate student who used a "Personal Scrum" methodology},
    posted-at = {2016-02-25 16:40:51},
    priority = {3},
    title = {{Personal Scrum | John Pruitt}},
    url = {http://blog.jgpruitt.com/tag/personal-scrum/}
}

@misc{DroneDevGuide,
    annote = {The developer guide for the AR Drone 2.0},
    author = {Piskorski, Stephane and Brulez, Nicolas and Eline, Pierre and D'Haeyer, Frederic},
    citeulike-article-id = {13938236},
    howpublished = {\\url{}},
    keywords = {api, development, drone},
    note = {Accessed February 2016},
    posted-at = {2016-02-22 13:55:22},
    priority = {2},
    title = {{AR.Drone Developer Guide}}
}

@misc{DroneQuickStart,
    annote = {The user guides for the drone, with safety guidelines in the quick start manual.},
    citeulike-article-id = {13938235},
    howpublished = {\\url{http://ardrone2.parrot.com/support/}},
    keywords = {drone, safety},
    note = {Accessed February 2016},
    posted-at = {2016-02-22 13:54:17},
    priority = {0},
    title = {{User guides for Ar.Drone 2.0}}
}

@misc{DroneAPI,
    annote = {A starting page for developers, allowing access to the SDK for the parrot drones.},
    citeulike-article-id = {13938234},
    howpublished = {\\url{http://developer.parrot.com/}},
    keywords = {api, drone},
    note = {Accessed February 2016},
    posted-at = {2016-02-22 13:53:41},
    priority = {0},
    title = {{Parrot for Developers}}
}

@misc{PersonalKanban,
    annote = {This site provides an explanation and guide for "Personal Kanban", which is a kanban system for personal work flows.},
    author = {Benson, Jim and Barry, Tonianne D.},
    citeulike-article-id = {13938233},
    howpublished = {\\url{http://www.personalkanban.com/}},
    keywords = {kanban, methodology, process},
    note = {Accessed February 2016},
    posted-at = {2016-02-22 13:52:38},
    priority = {0},
    title = {{Personal Kanban}}
}

@article{souhila2007optical,
    author = {Souhila, Kahlouche and Karim, Achour},
    citeulike-article-id = {13938190},
    citeulike-linkout-0 = {http://dx.doi.org/10.5772/5715},
    doi = {10.5772/5715},
    journal = {International Journal of Advanced Robotic Systems},
    keywords = {mmp, optical-flow, vision},
    number = {1},
    pages = {13--16},
    posted-at = {2016-02-22 12:46:16},
    priority = {2},
    title = {{Optical flow based robot obstacle avoidance}},
    url = {http://dx.doi.org/10.5772/5715},
    volume = {4},
    year = {2007},
    annote = {}
}

@inproceedings{citeulike:13938185,
    author = {Baratoff, G. and Toepfer, Christian and Wende, Moritz and Neumann, Heiko},
    booktitle = {Intelligent Control (ISIC), 1998. Held jointly with IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA), Intelligent Systems and Semiotics (ISAS), Proceedings},
    citeulike-article-id = {13938185},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/isic.1998.713676},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=713676},
    doi = {10.1109/isic.1998.713676},
    institution = {Dept. of Neural Inf. Process., Ulm Univ., Germany},
    isbn = {0-7803-4423-5},
    issn = {2158-9860},
    keywords = {mmp, optical-flow, vision},
    month = sep,
    pages = {289--294},
    posted-at = {2016-02-22 12:39:35},
    priority = {3},
    publisher = {IEEE},
    title = {{Real-time navigation and obstacle avoidance from optical flow on a space-variant map}},
    url = {http://dx.doi.org/10.1109/isic.1998.713676},
    year = {1998},
    annote = {A robotics system using optical flow as a method of avoiding obstacles.}
}

@article{citeulike:7356573,
    abstract = {{A model is presented, consonant with current views regarding the neurophysiology and psychophysics of motion perception, that combines the outputs of a set of spatiotemporal motion-energy filters to estimate image velocity. A parallel implementation computes a distributed representation of image velocity. A measure of image-flow uncertainty is formulated; preliminary results indicate that this uncertainty measure may be used to recognize ambiguity due to the aperture problem. The model appears to deal with the aperture problem as well as the human visual system since it extracts the correct velocity for some patterns that have large differences in contrast at different spatial orientations.}},
    author = {Heeger, DavidJ},
    booktitle = {International Journal of Computer Vision},
    citeulike-article-id = {7356573},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/bf00133568},
    citeulike-linkout-1 = {http://www.springerlink.com/content/jwmj25g544367p71},
    citeulike-linkout-2 = {http://link.springer.com/article/10.1007/BF00133568},
    day = {1},
    doi = {10.1007/bf00133568},
    issn = {0920-5691},
    journal = {International Journal of Computer Vision},
    keywords = {flow, mmp, optical, vision},
    month = jan,
    number = {4},
    pages = {279--302},
    posted-at = {2016-02-22 08:56:59},
    priority = {3},
    publisher = {Kluwer Academic Publishers},
    title = {{Optical flow using spatiotemporal filters}},
    url = {http://dx.doi.org/10.1007/bf00133568},
    volume = {1},
    year = {1988},
    annote = {A method of estimating image velocity using spatiotemporal filters, used to determine optical flow of an image.}
}

